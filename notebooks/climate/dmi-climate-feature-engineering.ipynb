{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8859c6a5-a98f-4d55-9305-a2d1eb224e80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.locate_filepaths import storage_filepaths\n",
    "from pyspark.sql.functions import avg, when, col, unix_timestamp\n",
    "from pyspark.sql.window import Window\n",
    "from src.etl.climate.feature_engineering import average_column_over_window, evaluate_null_columns\n",
    "\n",
    "# Loading data from silver layer.\n",
    "paths = storage_filepaths()\n",
    "df_climate = spark.read.format(\"delta\").load(f\"{paths['silver']}/dmi_climate_data\")\n",
    "\n",
    "# Grouping the features into average daily observations and all stations.\n",
    "# Averaging across astations as the covered area is not large (northern zealand + Copenhagen).\n",
    "df_climate = df_climate.groupBy('observed_date').agg(avg('sun_last1h_glob').alias('daily_avg_sun'), avg('temp_mean_past1h').alias('daily_avg_air_temp'), avg('temp_soil_mean_past1h').alias('daily_avg_soil_temp'), avg('precip_past1h').alias('daily_avg_rain'))\n",
    "\n",
    "# Adding columns: Precipication sum last week & Precipication sum last 2 weeks & Precipication last 4 weeks.\n",
    "# As it is believed that the precipication over time has a significant influence on the water level.\n",
    "for i in [7,14,30]:\n",
    "    df_climate = average_column_over_window(df=df_climate,\n",
    "                                            exist_col_name='daily_avg_rain',\n",
    "                                            new_col_name=f'{i}days_avg_rain',\n",
    "                                            time_days=i)\n",
    "\n",
    "# Substituting null values with -999\n",
    "# Adding not null columns for each feature column, so linear regression is able disregard columns with null values (-999).\n",
    "df_climate = evaluate_null_columns(df_climate,-999)\n",
    "\n",
    "\n",
    "# Exporting to gold layer.\n",
    "#df_climate.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"{paths['gold']}/climate_for_ml/\")\n",
    "#display(df_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d6c0b91-d9c8-435b-a441-080d4429f6a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_climate)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dmi-climate-feature-engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
