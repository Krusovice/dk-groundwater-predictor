{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8c7c559-7bad-4cd4-88fd-dc2111abb45d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.locate_filepaths import storage_filepaths\n",
    "import glob\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, TimestampType,DoubleType\n",
    "from pyspark.sql.functions import round, col, lit, split, current_timestamp, to_date\n",
    "paths = storage_filepaths()\n",
    "\n",
    "dbutils.widgets.text(\"source\", \"\")\n",
    "source = dbutils.widgets.get(\"source\")\n",
    "\n",
    "files = dbutils.fs.ls(f\"{paths['bronze']}/geus_groundwater/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d596587a-04bb-46db-b2f8-36622c52cf2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with station_id as key and station_name as value\n",
    "station_file = [i.path for i in files if i.path.endswith('.txt')][0]\n",
    "with open(station_file.replace('dbfs:','/dbfs'), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "station_dict = {}\n",
    "for i in lines:\n",
    "    key = i.split(',')[0]\n",
    "    values = i.split(',')[1:]\n",
    "    values_merged = \", \".join(s.strip() for s in values)\n",
    "    station_dict[key] = values_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84387182-9238-41d8-bdec-8213f2671a84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating an empty Spark DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"observed_timestamp\", TimestampType(), True),\n",
    "    StructField(\"waterlevel\", FloatType(), True),\n",
    "    StructField(\"station_id\", StringType(), True),\n",
    "    StructField(\"station_name\", StringType(), True),\n",
    "])\n",
    "\n",
    "empty_data = []\n",
    "df = spark.createDataFrame(empty_data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15829b0d-7be9-4f39-b3dc-5223be55236a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Applying groundwater data and station data for each groundwater item\n",
    "groundwater_files = [i.path for i in files if i.path.endswith('.csv')]\n",
    "\n",
    "for i in groundwater_files:\n",
    "    station_id = i.split('grundvandsstand_')[1].split('.csv')[0]\n",
    "    df_inc = spark.read.option(\"header\", \"true\").schema(schema).csv(i)\n",
    "    df_inc = df_inc.withColumn(\"waterlevel\", round(col(\"waterlevel\"),2))\n",
    "    df_inc = df_inc.withColumn(\"station_id\", lit(station_id))\n",
    "    df_inc = df_inc.withColumn(\"station_name\", lit(station_dict[station_id]))\n",
    "    df = df.union(df_inc)\n",
    "\n",
    "df = df.withColumn('ingestion_timestamp',current_timestamp())\n",
    "df = df.withColumn('observed_date', to_date(col(\"observed_timestamp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6120287-d0a8-474b-a497-7469ec5b2b65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Saving\n",
    "df.write.format(\"delta\").mode(\"overwrite\").partitionBy('station_id').save(f\"{paths['silver']}/geus_groundwater/\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "groundwater-clean",
   "widgets": {
    "source": {
     "currentValue": "",
     "nuid": "c366d64c-066b-4296-9b63-dcd69bfa357e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "source",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "source",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
