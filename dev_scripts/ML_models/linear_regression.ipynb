{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17204beb-5a0a-474c-ace7-c3d68953183d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.locate_filepaths import storage_filepaths\n",
    "from pyspark.sql.functions import col,avg, min, unix_timestamp\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paths = storage_filepaths()\n",
    "\n",
    "groundwater_df = spark.read.format('delta').load(f\"{paths['gold']}/groundwater_for_ml\")\n",
    "climate_df = spark.read.format('delta').load(f\"{paths['gold']}/climate_for_ml\")\n",
    "\n",
    "# Verifying dataframe format\n",
    "# display(groundwater_df)\n",
    "# display(climate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1da5e30-534d-4b2e-9bce-52c75c1e2783",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(groundwater_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be36cc22-5fae-438c-bf93-05970e561897",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Filtering groundwater_df for one station, as each ML model should be trained per station.\n",
    "# Due to different soil stratification, different groundwater level behaviours are expected per station.\n",
    "station_id_applied = '187.199'\n",
    "groundwater_df_filtered = groundwater_df.filter(col('station_id') == station_id_applied)\n",
    "\n",
    "# Joining climate and groundwater dataframes\n",
    "groundwater_df_filtered = groundwater_df_filtered.select(col('observed_date'), col('daily_avg_waterlevel'))\n",
    "climate_df = climate_df.join(groundwater_df_filtered, on='observed_date', how='inner')\n",
    "\n",
    "climate_df = climate_df.withColumn(\"date_ts\", unix_timestamp(\"observed_date\"))\n",
    "first_observation_day_ts = climate_df.select(min(\"date_ts\")).first()[0]\n",
    "climate_df = climate_df.filter(col('date_ts') > first_observation_day_ts+200*24*3600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b31789c-11a2-4c10-b8cd-c9d51c41f315",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Selecting feature columns\n",
    "feature_cols = [i for i in climate_df.columns if i not in ['observed_date', 'daily_avg_waterlevel']]\n",
    "\n",
    "# Assemble features into one vector column\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "df_vector = assembler.transform(climate_df)\n",
    "\n",
    "# Split into train/test sets\n",
    "train_df, test_df = df_vector.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Create and fit the linear regression model\n",
    "lr = LinearRegression(featuresCol='features', labelCol='daily_avg_waterlevel')\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Predicting on test values\n",
    "predictions = lr_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a12e450-6815-4313-b9aa-40bb68eb5569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plotting measured and predicted values on y axis, observed dates on x-axis.\n",
    "row = groundwater_df.filter(col(\"station_id\") == station_id_applied).first()\n",
    "location = row[\"station_name\"]\n",
    "\n",
    "plot_df = predictions.select(\"observed_date\", \"daily_avg_waterlevel\", \"prediction\",\"7days_avg_rain\").toPandas()\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(plot_df['observed_date'], plot_df['daily_avg_waterlevel'], label='Measured value')\n",
    "plt.plot(plot_df['observed_date'],plot_df['prediction'],label='Prediction')\n",
    "plt.title(f'Groundwater Prediction, Accuracy Plot\\nStation: {location}\\nR2={format(lr_model.summary.r2,\"0.2f\")}')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Groundwater level [m]')\n",
    "plt.grid()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"RMSE: {lr_model.summary.rootMeanSquaredError}\")\n",
    "print(f\"R2: {lr_model.summary.r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "linear_regression",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
