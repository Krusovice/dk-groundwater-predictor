{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17204beb-5a0a-474c-ace7-c3d68953183d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.locate_filepaths import storage_filepaths\n",
    "\n",
    "paths = storage_filepaths()\n",
    "\n",
    "groundwater_df = spark.read.format('delta').load(f\"{paths['gold']}/groundwater_for_ml\")\n",
    "climate_df = spark.read.format('delta').load(f\"{paths['gold']}/climate_for_ml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b13f6cb4-160f-4ad8-81d9-f5bbd022d345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#display(groundwater_df.limit(3))\n",
    "display(climate_df.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be36cc22-5fae-438c-bf93-05970e561897",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,avg\n",
    "\n",
    "\n",
    "groundwater_df = groundwater_df.filter(col('station_id') == '187.199')\n",
    "groundwater_df = groundwater_df.select(col('observed_date'), col('daily_avg_waterlevel'))\n",
    "\n",
    "climate_df = climate_df.join(groundwater_df, on='observed_date', how='inner')\n",
    "display(climate_df.orderBy(col('observed_date').desc()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b31789c-11a2-4c10-b8cd-c9d51c41f315",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "feature_cols = [i for i in climate_df.columns if i not in ['observed_date', 'daily_avg_waterlevel']]\n",
    "\n",
    "# Assemble features into one vector column\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "df_vector = assembler.transform(climate_df)\n",
    "\n",
    "# Split into train/test sets\n",
    "train_df, test_df = df_vector.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Create and fit the linear regression model\n",
    "lr = LinearRegression(featuresCol='features', labelCol='daily_avg_waterlevel')\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "predictions = lr_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a12e450-6815-4313-b9aa-40bb68eb5569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_df = predictions.select(\"observed_date\", \"daily_avg_waterlevel\", \"prediction\").toPandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(plot_df['observed_date'], plot_df['daily_avg_waterlevel'], label='Measured value')\n",
    "plt.plot(plot_df['observed_date'],plot_df['prediction'],label='Prediction')\n",
    "plt.legend()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"RMSE: {lr_model.summary.rootMeanSquaredError}\")\n",
    "print(f\"R2: {lr_model.summary.r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "linear_regression",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
